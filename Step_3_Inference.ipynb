{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3mK_kYvqi7N9",
        "outputId": "d3a3cf62-7188-42e9-fd7d-828541fbe542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'zero-shot-image-captioning'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 180 (delta 43), reused 0 (delta 0), pack-reused 89\u001b[K\n",
            "Receiving objects: 100% (180/180), 76.90 MiB | 19.38 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-fdld7odi\n",
            "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-fdld7odi\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.5)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.1)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.5.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.9.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 80.2 MB/s \n",
            "\u001b[?25hCollecting black==22.3.0\n",
            "  Downloading black-22.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 39.3 MB/s \n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 68.7 MB/s \n",
            "\u001b[?25hCollecting fairscale\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 29.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (4.1.1)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting platformdirs>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.10.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black==22.3.0->detectron2==0.6) (4.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.10.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 63.3 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from fairscale->detectron2==0.6) (1.12.1+cu113)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black==22.3.0->detectron2==0.6) (3.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.49.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.1)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm->detectron2==0.6) (0.13.1+cu113)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm->detectron2==0.6) (3.8.0)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp37-cp37m-linux_x86_64.whl size=4893352 sha256=4493ded0df1a8ba2dae0cea09fa3a848f0822b47a9434a0802490ea3b5494b8f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n8cfydr6/wheels/07/dc/32/0322cb484dbefab8b9366bfedbaff5060ac7d149d69c27ca5d\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=0dc5e191c8b757c137b7726d13fb0047c59496763d85b6f4b56f15db25d80ad8\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=20634bfc2503745c3126a0fb836361a46bc43b31ce6329274f6993f8d1e4866a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=7357afe08558c04a5f595996dfd8a4a62803fea526212b3cc7b5cf9ff3522621\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime fairscale\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, platformdirs, pathspec, omegaconf, mypy-extensions, iopath, huggingface-hub, click, timm, hydra-core, fvcore, fairscale, black, detectron2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 click-8.1.3 detectron2-0.6 fairscale-0.4.6 fvcore-0.1.5.post20220512 huggingface-hub-0.10.1 hydra-core-1.2.0 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.2.3 pathspec-0.10.1 platformdirs-2.5.2 portalocker-2.6.0 timm-0.6.11 typed-ast-1.5.4 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/CornerSiow/zero-shot-image-captioning.git\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cGGg2tZBjH5R"
      },
      "outputs": [],
      "source": [
        "!cp \"zero-shot-image-captioning/code/Vocabulary.py\" \"Vocabulary.py\"\n",
        "!cp \"zero-shot-image-captioning/code/DecoderLSTM.py\" \"DecoderLSTM.py\"\n",
        "!cp \"zero-shot-image-captioning/code/Places365.py\" \"Places365.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_aUvopAXjRn6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from DecoderLSTM import DecoderLSTM\n",
        "from Vocabulary import Vocabulary\n",
        "import pickle\n",
        "from Places365 import Places365\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import MetadataCatalog\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTJ41ZUmkco7",
        "outputId": "2565b2a2-cec2-4c3c-c095-e3d8e23405e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_cafdb1.pkl: 261MB [00:12, 21.5MB/s]                           \n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "place365 = Places365()\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "cfg.MODEL.DEVICE = str(device)\n",
        "detectron2 = DefaultPredictor(cfg)\n",
        "with open('zero-shot-image-captioning/data/filtered_symbolic.pickle', 'rb') as handle:\n",
        "    filtered_symbolic = pickle.load(handle)  \n",
        "vocab = Vocabulary()\n",
        "vocab.loadFile(\"zero-shot-image-captioning/data/vocab.pickle\")\n",
        "vocab_size = len(vocab)\n",
        "embed_size = len(filtered_symbolic)\n",
        "hidden_size = 256 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyN6Ty8akfdJ",
        "outputId": "3eabda52-47b7-4bd3-e25f-b97e06697fa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderLSTM(\n",
              "  (embedding): Embedding(30, 8)\n",
              "  (lstm): LSTM(8, 256, bias=False, batch_first=True)\n",
              "  (linear): Linear(in_features=256, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "decoder = DecoderLSTM(embed_size, hidden_size, vocab_size)\n",
        "decoder.load_state_dict(torch.load('zero-shot-image-captioning/data/lstm_decoder.pkl'))\n",
        "decoder.to(device)\n",
        "decoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IkDvbv7qlFHS"
      },
      "outputs": [],
      "source": [
        "def getImageSymbolics(img_path, threshold = 0.6):\n",
        "\n",
        "    result = place365.pred(img_path)\n",
        "   \n",
        "    im = cv2.imread(img_path)        \n",
        "    panoptic_seg, segments_info = detectron2(im)[\"panoptic_seg\"]\n",
        "    meta = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
        "\n",
        "    stuffClass = meta.stuff_classes\n",
        "    thingClass = meta.thing_classes\n",
        "\n",
        "    stuffResult = []\n",
        "    thingResult = []\n",
        "    areaSize = 0\n",
        "    \n",
        "    for v in segments_info:        \n",
        "        if v['isthing']:\n",
        "            thingResult.append([thingClass[v['category_id']].replace(\"-\", \" \").replace(\"/\", \" \").replace(\"_\", \" \"), v['score']])    \n",
        "        else:\n",
        "            areaSize = max(areaSize, v['area'])\n",
        "            stuffResult.append([stuffClass[v['category_id']].replace(\"-\", \" \").replace(\"/\", \" \").replace(\"_\", \" \"), v['area']])\n",
        "\n",
        "    \n",
        "    for v in thingResult:\n",
        "            if v[0] not in result:\n",
        "                result[v[0]] = 0\n",
        "            result[v[0]] += v[1]\n",
        "    \n",
        "    \n",
        "    for v in stuffResult:     \n",
        "            if v[0] not in result:\n",
        "                result[v[0]] = 0\n",
        "            result[v[0]] += v[1]/areaSize\n",
        "    \n",
        "    symbolics = {}\n",
        "    for r in result:\n",
        "        if result[r] > threshold:\n",
        "            symbolics[r] = result[r]\n",
        " \n",
        "    return symbolics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gGYJ4zKmCq0",
        "outputId": "c8b870c5-2b69-46a5-c7dc-1aeec16534ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "washing_2.jpg  a person washes his face in the sink\n",
            "washing_1.jpg  a person washes his face in the sink\n",
            "eating_2.jpg  a person eats a banana in front of a laptop\n",
            "eating_1.jpg  a person eats a banana in front of a laptop\n",
            "working_2.jpg  a person using a laptop in the office\n",
            "bus_2.jpg  someone is waiting at the bus stop\n",
            "cycling_1.jpg  a person riding a bike on a clear sky\n",
            "working_1.jpg  a person using a laptop in the office\n",
            "cycling_2.jpg  a person riding a bike on a clear sky\n",
            "bus_1.jpg  someone is waiting at the bus stop\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for filename in os.scandir(\"zero-shot-image-captioning/img_test\"):\n",
        "  if filename.path.endswith('jpg'):\n",
        "    symbolics = getImageSymbolics(filename.path)\n",
        "    inputs = np.zeros(len(filtered_symbolic))\n",
        "\n",
        "    for s in symbolics:\n",
        "        if s.replace(\" \", \"_\") in filtered_symbolic:\n",
        "          inputs[filtered_symbolic.index(s.replace(\" \", \"_\"))] = symbolics[s]\n",
        "    \n",
        "    inputs = torch.from_numpy(inputs).float()\n",
        "    inputs = inputs.unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "    output = decoder.sample(inputs)    \n",
        "    sentence = vocab.clean_sentence(output)        \n",
        "    print(filename.name, sentence)\n",
        "    results.append({\n",
        "        'name' : filename.name,\n",
        "        'path' : filename.path,\n",
        "        'caption': sentence\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlroow87pfhq"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "for v in results:\n",
        "  img = cv2.imread(v['path'])\n",
        "  cv2_imshow(img)\n",
        "  break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBaNsSqnuG3TNHzjlT0s8u"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}