# Zero-Shot Image Captioning
This is the code and dataset used in <paper>.

The reason why have this project is we found out it's hard to have a dataset to caption elderly life (include images), therefore, instead of collecting images from elderly life, we proposed using a model to learn from text, and then used any third-party detection tools to provide the detected symbolic result for the model to generate caption.


Feel free to use the code and cite the paper.
